{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HJJunn/sentence_order/blob/main/%EB%AC%B8%EC%9E%A5_%EC%88%9C%EC%84%9C_T5_epoch5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiKNz9s6XjV3",
        "outputId": "870dacf0-98b8-43d0-e94b-f7884b6bf36a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-gkI0JVNV9j",
        "outputId": "4d51b21f-72bc-4858-f668-e62288ab109c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFT5ForConditionalGeneration, T5TokenizerFast\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "yYE1m48ONZdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1) 데이터 확인"
      ],
      "metadata": {
        "id": "PxV3opajNu0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')"
      ],
      "metadata": {
        "id": "t3TXj1FXNtRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.isnull().sum())\n",
        "print(test.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGGqeHt3OX78",
        "outputId": "bc3eedf3-e6ae-4c05-c208-8d82b0e37ec0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID            0\n",
            "sentence_0    0\n",
            "sentence_1    0\n",
            "sentence_2    0\n",
            "sentence_3    0\n",
            "answer_0      0\n",
            "answer_1      0\n",
            "answer_2      0\n",
            "answer_3      0\n",
            "dtype: int64\n",
            "ID            0\n",
            "sentence_0    0\n",
            "sentence_1    0\n",
            "sentence_2    0\n",
            "sentence_3    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"학습 데이터 개수:\",len(train))\n",
        "print(\"테스트 데이터 개수:\", len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bU_NHdNXOhfJ",
        "outputId": "b8acf31b-6f1e-41cf-8809-3754786f4ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습 데이터 개수: 7351\n",
            "테스트 데이터 개수: 1780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2) 데이터 전처리"
      ],
      "metadata": {
        "id": "z4oFGC0mPcgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   sentence, answer끼리 하나로 합치기\n",
        "2.   sentence: 입력, answer = 레이블\n",
        "3.   입력 앞에 prefix 추가 : \"문장을 순서대로 정렬하세요: \"\n",
        "4.   문장 구분점 < /s > 삽입\n",
        "5.   입력 정수 인코딩\n",
        "6.   target 레이블을 문자열 형태로 변경 -> \"2 0 1 3\"\n"
      ],
      "metadata": {
        "id": "szPscqzbPxiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 텍스트와 타겟 텍스트를 구성하는 함수\n",
        "def make_input(row):\n",
        "    sentences = [row[f\"sentence_{i}\"] for i in range(4)]\n",
        "    input_text = \"문장을 순서대로 정렬하세요: \" + \" </s> \".join(sentences)\n",
        "    answer = [row[f\"answer_{i}\"] for i in range(4)]\n",
        "    target_text = \" \".join(map(str, answer))  # 예: \"0 3 1 2\"\n",
        "    return {\"input\": input_text, \"target\": target_text}"
      ],
      "metadata": {
        "id": "NsWDHCPOOuqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = train.apply(make_input, axis=1).tolist()\n",
        "train_data, valid_data = train_test_split(inputs, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "cQVxg3xvegAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "print(\"샘플의 최대 길이: %d\" % max(len(i['input']) for i in inputs))\n",
        "print(\"샘플의 최소 길이: %d\" % min(len(i['input']) for i in inputs))\n",
        "plt.hist([len(i['input']) for i in inputs], bins=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "_jXi0tCUhCqo",
        "outputId": "004a066a-d926-428d-b94a-b2eef4ee8095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플의 최대 길이: 304\n",
            "샘플의 최소 길이: 92\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.000e+00, 1.000e+00, 3.000e+00, 7.000e+00, 3.100e+01, 9.200e+01,\n",
              "        2.760e+02, 4.720e+02, 8.730e+02, 1.027e+03, 1.265e+03, 1.135e+03,\n",
              "        8.190e+02, 6.210e+02, 3.340e+02, 2.060e+02, 1.260e+02, 4.000e+01,\n",
              "        1.500e+01, 6.000e+00]),\n",
              " array([ 92. , 102.6, 113.2, 123.8, 134.4, 145. , 155.6, 166.2, 176.8,\n",
              "        187.4, 198. , 208.6, 219.2, 229.8, 240.4, 251. , 261.6, 272.2,\n",
              "        282.8, 293.4, 304. ]),\n",
              " <BarContainer object of 20 artists>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHeJUnIgf3EQ",
        "outputId": "2ebd6877-a333-41e5-e0bd-30f7505a3226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5880\n",
            "1471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class T5ReorderDataset(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, tokenizer, input_max_len, target_max_len, batch_size, ignore_index=-100):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.input_max_len = input_max_len\n",
        "        self.target_max_len = target_max_len\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.ignore_index = ignore_index\n",
        "        self.indices = list(range(len(self.data)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        start_idx = idx * self.batch_size\n",
        "        end_idx = start_idx + self.batch_size\n",
        "        if start_idx >= len(self.indices):\n",
        "            raise IndexError(f\"Invalid batch index: {idx}, start_idx {start_idx} >= {len(self.indices)}\")\n",
        "        batch_indices = self.indices[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
        "        batch = [self.data[i] for i in batch_indices]\n",
        "\n",
        "        input_ids = []\n",
        "        labels = []\n",
        "\n",
        "        for example in batch:\n",
        "            encoded_input = self.tokenizer.encode(\n",
        "                example[\"input\"],\n",
        "                max_length=self.input_max_len,\n",
        "                padding='max_length',\n",
        "                truncation=True\n",
        "            )\n",
        "            encoded_target = self.tokenizer.encode(\n",
        "                example[\"target\"],\n",
        "                max_length=self.target_max_len,\n",
        "                padding='max_length',\n",
        "                truncation=True\n",
        "            )\n",
        "\n",
        "            label = [token if token != self.tokenizer.pad_token_id else self.ignore_index\n",
        "                     for token in encoded_target]\n",
        "\n",
        "            input_ids.append(encoded_input)\n",
        "            labels.append(label)\n",
        "\n",
        "        return {\n",
        "            'input_ids': np.array(input_ids, dtype=np.int32),\n",
        "            'labels': np.array(labels, dtype=np.int32)\n",
        "        }\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "\n"
      ],
      "metadata": {
        "id": "QTHtF545WBS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3) 모델 클래스 선언"
      ],
      "metadata": {
        "id": "ieXV_0FnYsAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFT5ForConditionalGeneration.from_pretrained('paust/pko-t5-base' , from_pt = True)\n",
        "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUjyBuCyT2jZ",
        "outputId": "482ae9e9-26fc-4eb2-ee6b-b93471eff0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/initializers/initializers.py:121: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
            "- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4) 데이터 로더 변환"
      ],
      "metadata": {
        "id": "hG1tqdGWY2vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lr = 3e-5\n",
        "max_epochs = 7\n",
        "warmup_ratio = 0.1"
      ],
      "metadata": {
        "id": "Pj8epdBkaCi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = T5ReorderDataset(train_data, tokenizer, 256, 16, batch_size=8)\n",
        "valid_dataset = T5ReorderDataset(valid_data, tokenizer, 256, 16, batch_size=8)\n",
        "\n",
        "\n",
        "\n",
        "total_steps = len(train_dataset) * max_epochs\n",
        "warmup_steps = int(total_steps * warmup_ratio)\n",
        "lr_schedule = CosineDecay(initial_learning_rate = lr, decay_steps = total_steps)\n",
        "optimizer = Adam(learning_rate = lr_schedule)"
      ],
      "metadata": {
        "id": "c6gj0ZzfYyNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5) 데이터 확인"
      ],
      "metadata": {
        "id": "BnEpoirlgAdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫번째 샘플의 원문 텍스트:\", train_data[0]['input'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wE8EoJNRfqP_",
        "outputId": "d0b30023-7816-4e83-ffc4-2a5463043662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 샘플의 원문 텍스트: 문장을 순서대로 정렬하세요: 시민들이 의사 결정 과정에 참여함으로써, 정책의 신뢰성과 수용성이 증대된다. </s> 원자력 발전소의 안전성과 환경적 영향을 고려할 때, 효과적인 위험 거버넌스가 필수적이다. </s> 결국, 원자력 위험 거버넌스는 시민과의 협력을 통해 더욱 강화될 수 있다. </s> 이 과정에서 시민 참여는 투명성을 높이고, 지역 사회의 우려를 반영하는 중요한 역할을 한다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"정수 인코딩 및 패딩 결과:\", train_dataset[0]['input_ids'][0])\n",
        "print(\"텍스트 길이:\", len(train_dataset[0]['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvK8vKiPgGIX",
        "outputId": "1b6c4d6c-80a2-4e19-f6b1-1ee6c939fb26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "정수 인코딩 및 패딩 결과: [ 4321   291   222  4652   927   222 18817   963    27   222  2076  3708\n",
            "   222  2183   222  1530   222  1405   279   222  1466   584  3101    13\n",
            "   222  1769   302   222  3080  3339   222  5326 14613   222  9578   883\n",
            "    15   222     1   222  7765   589   222  1852   402   302   222   968\n",
            "  3339   222  1409   403   222  2075   291   222  2409   411   222   483\n",
            "    13   222  1440 34939   222  2399   222 31547   278   222 24446   570\n",
            "    15   222     1   222  1783    13   222  7765   589   222  2399   222\n",
            " 31547   274   222  2076  2526   222  2338   291   222   948   222  1546\n",
            "   222  1856   764   222   334   222   530    15   222     1   222   262\n",
            "   222  1405   389   222  2076   222  1466   274   222  3835   396   291\n",
            "   222  8917    13   222   828   222  1191   302   222  2835   333   222\n",
            "  3167   429   222  1317   305   222  2312   291   222   588    15     1\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0]\n",
            "텍스트 길이: 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫번째 샘플의 정수 인코딩 후 복원 결과:\", tokenizer.decode(train_dataset[0]['input_ids'][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlIUjEccggrT",
        "outputId": "5dd13f28-675f-4b53-8972-dba53d45fb9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 샘플의 정수 인코딩 후 복원 결과: 문장을 순서대로 정렬하세요: 시민들이 의사 결정 과정에 참여함으로써, 정책의 신뢰성과 수용성이 증대된다. </s> 원자력 발전소의 안전성과 환경적 영향을 고려할 때, 효과적인 위험 거버넌스가 필수적이다. </s> 결국, 원자력 위험 거버넌스는 시민과의 협력을 통해 더욱 강화될 수 있다. </s> 이 과정에서 시민 참여는 투명성을 높이고, 지역 사회의 우려를 반영하는 중요한 역할을 한다.</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫번째 샘플의 레이블:\" , train_data[0]['target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOLMEDVSgybS",
        "outputId": "4eeddad9-1a54-48c1-a70c-10fde26497f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 샘플의 레이블: 1 3 0 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ID 222의 토큰:\", tokenizer.convert_ids_to_tokens(222))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1tZInslzho_",
        "outputId": "6f6b5f15-9a47-4f71-e4da-3b8cf48fca3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID 222의 토큰: Ġ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"첫번째 샘플의 레이블의 정수 인코딩 및 패딩 결과:\", train_dataset[0]['labels'][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOKROfkqid3o",
        "outputId": "58654e3b-9b62-4545-9a3c-1fd9238c86a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 샘플의 레이블의 정수 인코딩 및 패딩 결과: [  18  222   20  222   17  222   19    1 -100 -100 -100 -100 -100 -100\n",
            " -100 -100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_array = train_dataset[0]['labels'][0]\n",
        "test_array[test_array == -100] = 0\n",
        "\n",
        "print(\"첫번째 샘플의 레이블:\", tokenizer.decode(test_array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmFuAAajijfp",
        "outputId": "9693da49-b40e-432f-c81f-fa51ab25c11f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫번째 샘플의 레이블: 1 3 0 2</s><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6) 어텐션 마스크 함수"
      ],
      "metadata": {
        "id": "xkj8d13Ei8Vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_attention_mask(input_ids):\n",
        "    input_ids = tf.convert_to_tensor(input_ids)\n",
        "    boolean_mask = tf.not_equal(input_ids, tokenizer.pad_token_id)\n",
        "    return tf.cast(boolean_mask, tf.float32)"
      ],
      "metadata": {
        "id": "8ntSUUp-itZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7) 학습"
      ],
      "metadata": {
        "id": "DkUOYDegjHi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = '/content/drive/MyDrive/Colab Notebooks/t5_reorder_model'"
      ],
      "metadata": {
        "id": "x_4wTrb0kIhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFT5ForConditionalGeneration\n",
        "\n",
        "# 1. 저장된 모델 불러오기\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/t5_reorder_model\"\n",
        "model = TFT5ForConditionalGeneration.from_pretrained(save_path)\n",
        "\n",
        "# 2. 이어서 학습\n",
        "best_loss = 0.1052\n",
        "start_epoch = 5\n",
        "max_epochs = 7\n",
        "\n",
        "for epoch in range(start_epoch, max_epochs):\n",
        "    print(f'에포크 {epoch+1}/ {max_epochs}')\n",
        "\n",
        "    total_train_loss = 0.0\n",
        "    for batch in tqdm(train_dataset, total=len(train_dataset), desc='훈련중'):\n",
        "        attention_mask = create_attention_mask(batch['input_ids'])\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = model(input_ids=batch['input_ids'],\n",
        "                            attention_mask=attention_mask,\n",
        "                            labels=batch['labels'],\n",
        "                            training=True)\n",
        "            loss = tf.cast(outputs.loss, tf.float32)\n",
        "\n",
        "        total_train_loss += tf.reduce_mean(loss).numpy()\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataset)\n",
        "    print(f'훈련 손실 : {avg_train_loss: .4f}')\n",
        "\n",
        "    # 검증\n",
        "    total_val_loss = 0.0\n",
        "    for batch in tqdm(valid_dataset, total=len(valid_dataset), desc='검증 중'):\n",
        "        attention_mask = create_attention_mask(batch['input_ids'])\n",
        "        outputs = model(input_ids=batch['input_ids'],\n",
        "                        attention_mask=attention_mask,\n",
        "                        labels=batch['labels'],\n",
        "                        training=False)\n",
        "        total_val_loss += tf.reduce_mean(outputs.loss).numpy()\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(valid_dataset)\n",
        "    print(f\"검증 손실 :  {avg_val_loss: .4f}\")\n",
        "\n",
        "    if avg_val_loss < best_loss:\n",
        "        best_loss = avg_val_loss\n",
        "        model.save_pretrained(save_path)\n",
        "        print(f\"검증 손실이 {best_loss: .4f}로 개선\")\n",
        "\n",
        "    train_dataset.on_epoch_end()\n",
        "\n",
        "print(\"훈련이 완료되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UEzrRqB7tL8",
        "outputId": "c6a55a86-66e3-4e83-e42a-9deac887c501"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "All the layers of TFT5ForConditionalGeneration were initialized from the model checkpoint at /content/drive/MyDrive/Colab Notebooks/t5_reorder_model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 6/ 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "훈련중: 100%|██████████| 735/735 [33:24<00:00,  2.73s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 손실 :  0.0961\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "검증 중: 184it [01:37,  1.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 손실 :   0.1000\n",
            "검증 손실이  0.1000로 개선\n",
            "에포크 7/ 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "훈련중: 100%|██████████| 735/735 [32:44<00:00,  2.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 손실 :  0.0767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "검증 중: 184it [01:35,  1.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "검증 손실 :   0.1004\n",
            "훈련이 완료되었습니다.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8) 추론"
      ],
      "metadata": {
        "id": "4ZSM8hOtb016"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터\n",
        "test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "sentences = test[[f\"sentence_{i}\" for i in range(4)]].values.tolist()"
      ],
      "metadata": {
        "id": "afD8yFueGMvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def reorder_batch(sent_batch, tokenizer, model, batch_size=16):\n",
        "    predictions = []\n",
        "    for i in tqdm(range(0, len(sent_batch), batch_size), desc=\"Predicting batches\"):\n",
        "        batch = sent_batch[i:i + batch_size]\n",
        "\n",
        "        input_texts = [\"문장을 순서대로 정렬하세요: \" + \" </s> \".join(sents) for sents in batch]\n",
        "\n",
        "        inputs = tokenizer(\n",
        "            input_texts,\n",
        "            return_tensors=\"tf\",\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            max_length=256\n",
        "        )\n",
        "\n",
        "        attention_mask = tf.cast(tf.not_equal(inputs['input_ids'], tokenizer.pad_token_id), tf.float32)\n",
        "\n",
        "        reorder_ids = model.generate(\n",
        "            input_ids=inputs['input_ids'],\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=16,\n",
        "            num_beams=1\n",
        "        )\n",
        "\n",
        "        decoded_batch = tokenizer.batch_decode(reorder_ids, skip_special_tokens=True)\n",
        "\n",
        "        for decoded in decoded_batch:\n",
        "            try:\n",
        "                order = list(map(int, decoded.strip().split()))\n",
        "                predictions.append(order)\n",
        "            except:\n",
        "                predictions.append([0, 1, 2, 3])  # fallback 예측\n",
        "    return predictions\n",
        "\n",
        "predictions = reorder_batch(sentences, tokenizer, model, batch_size=16)\n"
      ],
      "metadata": {
        "id": "WgYZoabyb4FY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df74db47-96f9-4841-cd99-1c0f76d6efd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Predicting batches: 100%|██████████| 112/112 [05:00<00:00,  2.68s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# true_orders는 문장 리스트 (기존)\n",
        "true_orders = test[[f\"sentence_{i}\" for i in range(4)]].values.tolist()\n",
        "\n",
        "# predictions가 인덱스 리스트이니, 예측 문장 리스트로 변환\n",
        "predicted_sentences = []\n",
        "for pred_idx_list, sentences in zip(predictions, true_orders):\n",
        "    ordered_sentences = [sentences[i] for i in pred_idx_list]\n",
        "    predicted_sentences.append(ordered_sentences)\n",
        "\n",
        "# 이제 predicted_sentences와 true_orders 비교\n",
        "exact_matches = sum([pred == true for pred, true in zip(predicted_sentences, true_orders)])\n",
        "exact_accuracy = exact_matches / len(predictions)\n",
        "\n",
        "# 부분 정확도\n",
        "partial_accuracies = []\n",
        "for pred, true in zip(predicted_sentences, true_orders):\n",
        "    correct_positions = sum([p == t for p, t in zip(pred, true)])\n",
        "    partial_accuracies.append(correct_positions / len(pred))\n",
        "\n",
        "average_partial_accuracy = np.mean(partial_accuracies)\n",
        "\n",
        "print(\"전체 정확도 (Exact Match Accuracy):\", round(exact_accuracy, 4))\n",
        "print(\"부분 정확도 평균 (Average Position Accuracy):\", round(average_partial_accuracy, 4))\n",
        "print(\"총 샘플 수:\", len(predictions))\n"
      ],
      "metadata": {
        "id": "ZIDzW3mMdYhr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10400dd4-b7ef-4c32-c84f-6a58959398d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "전체 정확도 (Exact Match Accuracy): 0.0365\n",
            "부분 정확도 평균 (Average Position Accuracy): 0.2576\n",
            "총 샘플 수: 1780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):  # 앞 5개 샘플만 출력\n",
        "    print(f\"샘플 {i+1}\")\n",
        "    print(\"원문 문장들:\")\n",
        "    for idx, sent in enumerate(true_orders[i]):\n",
        "        print(f\"  문장 {idx}: {sent}\")\n",
        "    print(\"모델 예측 순서 인덱스:\", predictions[i])\n",
        "    print(\"모델이 예측한 문장 순서:\")\n",
        "    for j, pred_idx in enumerate(predictions[i]):\n",
        "        print(f\"  위치 {j}: {true_orders[i][pred_idx]}\")\n",
        "    print(\"정답 문장 순서:\")\n",
        "    for j, sent in enumerate(true_orders[i]):\n",
        "        print(f\"  위치 {j}: {sent}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "wwfLxeAZiOXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d5c7d7-064f-4193-ec27-253031bb4600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 1\n",
            "원문 문장들:\n",
            "  문장 0: 자유 의지와 결정론은 서로 상충하는 개념으로 여겨지지만, 이 둘의 공존 가능성도 탐구할 가치가 있다.\n",
            "  문장 1: 결정론은 모든 사건이 원인과 결과의 연쇄에 의해 발생한다고 주장하며, 이는 인간의 행동에도 적용될 수 있다.\n",
            "  문장 2: 그러나 인간의 인식과 선택 과정에서 나타나는 복잡성과 예측 불가능성은 자유 의지의 존재를 시사한다.\n",
            "  문장 3: 결국, 자유 의지와 결정론은 서로를 배제하기보다는, 인간 경험의 다양한 측면을 설명하는 데 기여할 수 있는 상호 보완적인 개념으로 이해될 수 있다.\n",
            "모델 예측 순서 인덱스: [0, 1, 2, 3]\n",
            "모델이 예측한 문장 순서:\n",
            "  위치 0: 자유 의지와 결정론은 서로 상충하는 개념으로 여겨지지만, 이 둘의 공존 가능성도 탐구할 가치가 있다.\n",
            "  위치 1: 결정론은 모든 사건이 원인과 결과의 연쇄에 의해 발생한다고 주장하며, 이는 인간의 행동에도 적용될 수 있다.\n",
            "  위치 2: 그러나 인간의 인식과 선택 과정에서 나타나는 복잡성과 예측 불가능성은 자유 의지의 존재를 시사한다.\n",
            "  위치 3: 결국, 자유 의지와 결정론은 서로를 배제하기보다는, 인간 경험의 다양한 측면을 설명하는 데 기여할 수 있는 상호 보완적인 개념으로 이해될 수 있다.\n",
            "정답 문장 순서:\n",
            "  위치 0: 자유 의지와 결정론은 서로 상충하는 개념으로 여겨지지만, 이 둘의 공존 가능성도 탐구할 가치가 있다.\n",
            "  위치 1: 결정론은 모든 사건이 원인과 결과의 연쇄에 의해 발생한다고 주장하며, 이는 인간의 행동에도 적용될 수 있다.\n",
            "  위치 2: 그러나 인간의 인식과 선택 과정에서 나타나는 복잡성과 예측 불가능성은 자유 의지의 존재를 시사한다.\n",
            "  위치 3: 결국, 자유 의지와 결정론은 서로를 배제하기보다는, 인간 경험의 다양한 측면을 설명하는 데 기여할 수 있는 상호 보완적인 개념으로 이해될 수 있다.\n",
            "--------------------------------------------------\n",
            "샘플 2\n",
            "원문 문장들:\n",
            "  문장 0: 사회적 낙인은 개인의 자아 존중감에 부정적인 영향을 미친다.\n",
            "  문장 1: 건강 불평등은 이러한 낙인으로 인해 더욱 심화되며, 특정 집단이 의료 서비스 접근에서 불이익을 겪게 만든다.\n",
            "  문장 2: 결국, 사회적 낙인과 건강 불평등은 서로 연결되어 있으며, 이를 해결하기 위한 포괄적인 접근이 필요하다.\n",
            "  문장 3: 낙인으로 인해 사람들은 사회적 고립을 경험하고, 이는 정신적 및 신체적 건강에 악영향을 미친다.\n",
            "모델 예측 순서 인덱스: [0, 3, 1, 2]\n",
            "모델이 예측한 문장 순서:\n",
            "  위치 0: 사회적 낙인은 개인의 자아 존중감에 부정적인 영향을 미친다.\n",
            "  위치 1: 낙인으로 인해 사람들은 사회적 고립을 경험하고, 이는 정신적 및 신체적 건강에 악영향을 미친다.\n",
            "  위치 2: 건강 불평등은 이러한 낙인으로 인해 더욱 심화되며, 특정 집단이 의료 서비스 접근에서 불이익을 겪게 만든다.\n",
            "  위치 3: 결국, 사회적 낙인과 건강 불평등은 서로 연결되어 있으며, 이를 해결하기 위한 포괄적인 접근이 필요하다.\n",
            "정답 문장 순서:\n",
            "  위치 0: 사회적 낙인은 개인의 자아 존중감에 부정적인 영향을 미친다.\n",
            "  위치 1: 건강 불평등은 이러한 낙인으로 인해 더욱 심화되며, 특정 집단이 의료 서비스 접근에서 불이익을 겪게 만든다.\n",
            "  위치 2: 결국, 사회적 낙인과 건강 불평등은 서로 연결되어 있으며, 이를 해결하기 위한 포괄적인 접근이 필요하다.\n",
            "  위치 3: 낙인으로 인해 사람들은 사회적 고립을 경험하고, 이는 정신적 및 신체적 건강에 악영향을 미친다.\n",
            "--------------------------------------------------\n",
            "샘플 3\n",
            "원문 문장들:\n",
            "  문장 0: 글쓰기 능력을 키우기 위해서는 꾸준한 연습이 필수적이다.\n",
            "  문장 1: 마지막으로, 독서를 통해 다른 작가들의 기법을 배우는 것은 창의력을 자극하는 데 도움이 된다.\n",
            "  문장 2: 피드백을 받는 과정은 글의 질을 향상시키는 중요한 요소로 작용한다.\n",
            "  문장 3: 다양한 주제에 대해 글을 써보면 자신의 스타일과 강점을 발견할 수 있다.\n",
            "모델 예측 순서 인덱스: [0, 3, 2, 1]\n",
            "모델이 예측한 문장 순서:\n",
            "  위치 0: 글쓰기 능력을 키우기 위해서는 꾸준한 연습이 필수적이다.\n",
            "  위치 1: 다양한 주제에 대해 글을 써보면 자신의 스타일과 강점을 발견할 수 있다.\n",
            "  위치 2: 피드백을 받는 과정은 글의 질을 향상시키는 중요한 요소로 작용한다.\n",
            "  위치 3: 마지막으로, 독서를 통해 다른 작가들의 기법을 배우는 것은 창의력을 자극하는 데 도움이 된다.\n",
            "정답 문장 순서:\n",
            "  위치 0: 글쓰기 능력을 키우기 위해서는 꾸준한 연습이 필수적이다.\n",
            "  위치 1: 마지막으로, 독서를 통해 다른 작가들의 기법을 배우는 것은 창의력을 자극하는 데 도움이 된다.\n",
            "  위치 2: 피드백을 받는 과정은 글의 질을 향상시키는 중요한 요소로 작용한다.\n",
            "  위치 3: 다양한 주제에 대해 글을 써보면 자신의 스타일과 강점을 발견할 수 있다.\n",
            "--------------------------------------------------\n",
            "샘플 4\n",
            "원문 문장들:\n",
            "  문장 0: 작은 공간에서도 효율적으로 사용할 수 있어 집안의 혼잡함을 줄여준다.\n",
            "  문장 1: 정기적으로 내용을 점검하면 필요 없는 물건을 정리할 수 있다.\n",
            "  문장 2: 각 칸을 활용하여 카테고리별로 물건을 나누면 찾기 쉬워진다.\n",
            "  문장 3: 다용도 수납함은 다양한 물건을 정리하는 데 유용하다.\n",
            "모델 예측 순서 인덱스: [3, 2, 0, 1]\n",
            "모델이 예측한 문장 순서:\n",
            "  위치 0: 다용도 수납함은 다양한 물건을 정리하는 데 유용하다.\n",
            "  위치 1: 각 칸을 활용하여 카테고리별로 물건을 나누면 찾기 쉬워진다.\n",
            "  위치 2: 작은 공간에서도 효율적으로 사용할 수 있어 집안의 혼잡함을 줄여준다.\n",
            "  위치 3: 정기적으로 내용을 점검하면 필요 없는 물건을 정리할 수 있다.\n",
            "정답 문장 순서:\n",
            "  위치 0: 작은 공간에서도 효율적으로 사용할 수 있어 집안의 혼잡함을 줄여준다.\n",
            "  위치 1: 정기적으로 내용을 점검하면 필요 없는 물건을 정리할 수 있다.\n",
            "  위치 2: 각 칸을 활용하여 카테고리별로 물건을 나누면 찾기 쉬워진다.\n",
            "  위치 3: 다용도 수납함은 다양한 물건을 정리하는 데 유용하다.\n",
            "--------------------------------------------------\n",
            "샘플 5\n",
            "원문 문장들:\n",
            "  문장 0: 음악은 특정 문화의 가치와 전통을 반영하는 중요한 매체이다.\n",
            "  문장 1: 이러한 음악적 표현은 공동체의 소속감을 증진시키는 역할을 한다.\n",
            "  문장 2: 각 문화는 고유한 음악적 요소를 통해 정체성을 형성하고 강화한다.\n",
            "  문장 3: 결국, 음악은 개인과 집단의 문화적 정체성을 이해하는 데 필수적인 요소로 작용한다.\n",
            "모델 예측 순서 인덱스: [0, 2, 1, 3]\n",
            "모델이 예측한 문장 순서:\n",
            "  위치 0: 음악은 특정 문화의 가치와 전통을 반영하는 중요한 매체이다.\n",
            "  위치 1: 각 문화는 고유한 음악적 요소를 통해 정체성을 형성하고 강화한다.\n",
            "  위치 2: 이러한 음악적 표현은 공동체의 소속감을 증진시키는 역할을 한다.\n",
            "  위치 3: 결국, 음악은 개인과 집단의 문화적 정체성을 이해하는 데 필수적인 요소로 작용한다.\n",
            "정답 문장 순서:\n",
            "  위치 0: 음악은 특정 문화의 가치와 전통을 반영하는 중요한 매체이다.\n",
            "  위치 1: 이러한 음악적 표현은 공동체의 소속감을 증진시키는 역할을 한다.\n",
            "  위치 2: 각 문화는 고유한 음악적 요소를 통해 정체성을 형성하고 강화한다.\n",
            "  위치 3: 결국, 음악은 개인과 집단의 문화적 정체성을 이해하는 데 필수적인 요소로 작용한다.\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sample_submission 불러오기\n",
        "sample_submission = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/sample_submission.csv\")\n",
        "\n",
        "# 예측 결과 적용\n",
        "for i in range(4):\n",
        "    sample_submission[f\"answer_{i}\"] = [\n",
        "        pred[i] if len(pred) == 4 else i for pred in predictions\n",
        "    ]\n",
        "\n",
        "# 저장 경로 설정\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/문맥 기반 문장 순서 예측_T5.csv\"\n",
        "\n",
        "# 저장\n",
        "sample_submission.to_csv(save_path, index=False)\n"
      ],
      "metadata": {
        "id": "7F0wzcvmg7kQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PoxJ_HaGjOTj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}